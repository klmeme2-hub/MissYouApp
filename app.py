import streamlit as st
import requests
from openai import OpenAI
from supabase import create_client, Client
import numpy as np
import os
import json
import io
from pydub import AudioSegment

# ==========================================
# ç‰ˆæœ¬è³‡è¨Šï¼šA ç‰ˆ (Master)
# æ›´æ–°å…§å®¹ï¼šè£œå›é€²åº¦æ¢ã€é›™æ¬„ä½ˆå±€ã€è©¦è½åŠŸèƒ½ã€å®Œç¾æš±ç¨±æ‹¼æ¥
# ==========================================

# --- 1. é é¢èˆ‡ UI è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="wide") # å¯¬è¢å¹•æ¨¡å¼

custom_css = """
<style>
    /* å…¨å±€é…è‰²é–å®š */
    .stApp, p, h1, h2, h3, label, div, span, button { color: #333333 !important; }
    
    /* ä¸‹æ‹‰é¸å–®ä¿®å¾© */
    div[data-baseweb="select"] > div { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li:hover { background-color: #E3F2FD !important; }

    /* AI å°è©±æ°£æ³¡ */
    .ai-bubble {
        background-color: #FFFFFF;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        border-left: 5px solid #4A90E2;
        margin: 10px 0;
        color: #333333;
    }
    
    /* é¡Œç›®å¡ç‰‡ (Active) */
    .question-card-active {
        background-color: #E3F2FD;
        padding: 20px;
        border-radius: 12px;
        margin-bottom: 20px;
        border: 2px solid #2196F3;
        text-align: center;
    }
    .q-text {
        font-size: 20px;
        font-weight: bold;
        color: #1565C0 !important;
        margin-bottom: 10px;
    }

    /* æ­·å²å›æ†¶å¡ç‰‡ */
    .history-card {
        background-color: #FFFFFF;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #E0E0E0;
        margin-bottom: 10px;
        font-size: 14px;
    }
    .history-q { font-weight: bold; color: #555 !important; }
    .history-a { color: #333 !important; margin-top: 5px; }
    
    /* å„€è¡¨æ¿å¡ç‰‡ */
    .dashboard-card {
        background-color: #FFFFFF;
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #E0E0E0;
        margin-bottom: 20px;
    }

    /* éš±è— Streamlit é¸å–® */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- 2. åˆå§‹åŒ–èˆ‡è¨­å®š ---
if "SUPABASE_URL" not in st.secrets or "ADMIN_PASSWORD" not in st.secrets:
    st.error("âš ï¸ è«‹å…ˆè¨­å®š Secrets")
    st.stop()

openai_key = st.secrets["OPENAI_API_KEY"]
elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
voice_id = st.secrets["VOICE_ID"]
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
admin_password = st.secrets["ADMIN_PASSWORD"]

client = OpenAI(api_key=openai_key)

@st.cache_resource
def init_supabase():
    return create_client(supabase_url, supabase_key)

supabase = init_supabase()

ROLE_MAPPING = {
    "å¦»å­": "wife",
    "ä¸ˆå¤«": "husband",
    "å…’å­": "son",
    "å¥³å…’": "daughter",
    "æœ‹å‹": "friend",
    "å­«å­": "grandson",
    "å…¶ä»–": "others"
}

# --- 3. è®€å–å¤–éƒ¨é¡Œåº« ---
@st.cache_data
def load_questions_from_file():
    try:
        with open('questions.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

question_db = load_questions_from_file()

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

def get_elevenlabs_usage():
    try:
        url = "https://api.elevenlabs.io/v1/user/subscription"
        headers = {"xi-api-key": elevenlabs_key}
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()
            return data['character_count'], data['character_limit']
        return 0, 0
    except: return 0, 0

def get_embedding(text):
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def get_memories_by_role(role):
    """å–å¾—è©²è§’è‰²æ‰€æœ‰çš„å›æ†¶"""
    try:
        response = supabase.table("memories").select("*").eq("role", role).order('id', desc=True).execute()
        return response.data
    except: return []

def save_memory_fragment(role, question, answer):
    """å„²å­˜è¨˜æ†¶ (å«è¦†å¯«é‚è¼¯ï¼šåˆªé™¤èˆŠçš„ç›¸åŒé¡Œç›®)"""
    full_content = f"ã€é—œæ–¼{question}ã€‘ï¼š{answer}"
    
    # 1. åˆªé™¤èˆŠçš„
    try:
        existing = get_memories_by_role(role)
        for mem in existing:
            # ç°¡å–®æ¯”å°é¡Œç›®
            if mem['content'].startswith(f"ã€é—œæ–¼{question}ã€‘"):
                supabase.table("memories").delete().eq("id", mem['id']).execute()
    except: pass
    
    # 2. æ’å…¥æ–°çš„
    embedding = get_embedding(full_content)
    data = {"role": role, "content": full_content, "embedding": embedding}
    supabase.table("memories").insert(data).execute()
    return True

def search_relevant_memories(role, query_text):
    try:
        query_vec = get_embedding(query_text)
        response = supabase.rpc(
            "match_memories",
            {"query_embedding": query_vec, "match_threshold": 0.5, "match_count": 3, "search_role": role}
        ).execute()
        return "\n".join([item['content'] for item in response.data])
    except: return ""

def save_persona_summary(role, content):
    data = {"role": role, "content": content}
    supabase.table("personas").upsert(data).execute()

def load_all_roles():
    try:
        res = supabase.table("personas").select("role").execute()
        return [i['role'] for i in res.data]
    except: return []

def load_persona(role):
    try:
        res = supabase.table("personas").select("content").eq("role", role).execute()
        return res.data[0]['content'] if res.data else None
    except: return None

# --- éŸ³è¨Šç›¸é—œå‡½æ•¸ ---
def upload_nickname_audio(role, audio_bytes):
    try:
        safe_role = ROLE_MAPPING.get(role, "others")
        file_path = f"nickname_{safe_role}.mp3"
        supabase.storage.from_("audio_clips").upload(
            file_path, audio_bytes, file_options={"content-type": "audio/mpeg", "upsert": "true"}
        )
        return True
    except Exception as e:
        st.error(f"å„²å­˜éŸ³æª”å¤±æ•—: {e}")
        return False

def get_nickname_audio_bytes(role):
    try:
        safe_role = ROLE_MAPPING.get(role, "others")
        file_path = f"nickname_{safe_role}.mp3"
        response = supabase.storage.from_("audio_clips").download(file_path)
        return response
    except: return None

def train_voice_sample(audio_bytes):
    try:
        url = f"https://api.elevenlabs.io/v1/voices/{voice_id}/edit"
        headers = {"xi-api-key": elevenlabs_key}
        files = {'files': ('training_sample.mp3', audio_bytes, 'audio/mpeg')}
        data = {'name': 'My Digital Clone'} 
        response = requests.post(url, headers=headers, data=data, files=files)
        return response.status_code == 200
    except Exception as e:
        print(f"è¨“ç·´ä¸Šå‚³å¤±æ•—: {e}")
        return False

def merge_audio_clips(intro_bytes, main_bytes):
    try:
        if not intro_bytes or len(intro_bytes) < 100: return main_bytes
        intro = AudioSegment.from_file(io.BytesIO(intro_bytes))
        main = AudioSegment.from_file(io.BytesIO(main_bytes))
        silence = AudioSegment.silent(duration=200)
        combined = intro + silence + main
        buffer = io.BytesIO()
        combined.export(buffer, format="mp3")
        return buffer.getvalue()
    except Exception as e:
        print(f"éŸ³è¨Šåˆä½µå¤±æ•—: {e}")
        return main_bytes

# --- 5. æ¬Šé™ç®¡ç† ---
if "is_admin" not in st.session_state: st.session_state.is_admin = False

def check_pass():
    if st.session_state.pwd_input == admin_password:
        st.session_state.is_admin = True
        st.session_state.pwd_input = ""
    else: st.error("å¯†ç¢¼éŒ¯èª¤")

# --- 6. ä¸»ä»‹é¢ ---
st.title("ğŸ¤ æƒ³å¿µ")

if not st.session_state.is_admin:
    # === è¦ªå‹å‰å° (User Mode) ===
    roles = load_all_roles()
    
    # é™åˆ¶å‰å°å¯¬åº¦
    st.markdown("""<style>.block-container {max_width: 700px; padding-top: 2rem;}</style>""", unsafe_allow_html=True)

    if not roles:
        st.info("â˜ï¸ å°šæœªå»ºç«‹æ•¸ä½äººæ ¼")
    else:
        col_sel, col_pic = st.columns([2, 1])
        with col_sel:
            st.markdown("#### ğŸ‘‹ æ‚¨å¥½ï¼Œè«‹å•æ‚¨æ˜¯æˆ‘çš„...ï¼Ÿ")
            sel_role = st.selectbox("èº«åˆ†", roles, label_visibility="collapsed")
            persona_summary = load_persona(sel_role)
            if persona_summary: st.success(f"å·²é€£çµï¼š{sel_role}æ¨¡å¼")
        with col_pic:
            if os.path.exists("photo.jpg"): st.image("photo.jpg", use_container_width=True)

        if "chat_history" not in st.session_state: st.session_state.chat_history = []

        def process_chat(audio_file):
            try:
                # 1. èªéŸ³è½‰å­—
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
                user_text = transcript.text
                if not user_text or len(user_text.strip()) < 2:
                    st.warning("ğŸ‘‚ è«‹å†èªªä¸€æ¬¡..."); return

                # 2. æª¢ç´¢è¨˜æ†¶
                with st.spinner("æ€è€ƒèˆ‡æª¢ç´¢ä¸­..."):
                    relevant_memory = search_relevant_memories(sel_role, user_text)
                    has_nickname_audio = get_nickname_audio_bytes(sel_role) is not None
                    
                    nickname_instruction = ""
                    if has_nickname_audio:
                        nickname_instruction = "ã€ç‰¹æ®ŠæŒ‡ä»¤ã€‘ï¼šå›æ‡‰ä¸­**çµ•å°ä¸è¦**åŒ…å«å°æ–¹çš„æš±ç¨±æˆ–æ‰“æ‹›å‘¼ï¼Œç›´æ¥è¬›å…§å®¹ã€‚å› ç‚ºç³»çµ±æœƒè‡ªå‹•æ’­æ”¾çœŸå¯¦æš±ç¨±ã€‚"
                    else:
                        nickname_instruction = "è«‹åœ¨é–‹é ­è‡ªç„¶å‘¼å–šå°æ–¹çš„æš±ç¨±ã€‚"

                    system_instruction = f"""
                    {persona_summary}
                    ã€æ·±å±¤è¨˜æ†¶ã€‘ï¼š{relevant_memory}
                    {nickname_instruction}
                    èªæ°£è¦è‡ªç„¶ï¼ŒåŒ…å«å‘¼å¸æ„Ÿã€‚
                    """
                    
                    msgs = [{"role": "system", "content": system_instruction}] + st.session_state.chat_history[-6:]
                    msgs.append({"role": "user", "content": user_text})

                    res = client.chat.completions.create(model="gpt-4o-mini", messages=msgs)
                    ai_text = res.choices[0].message.content
                    
                    st.session_state.chat_history.append({"role": "user", "content": user_text})
                    st.session_state.chat_history.append({"role": "assistant", "content": ai_text})

                    final_audio_bytes = b""
                    ai_audio_bytes = b""

                    if ai_text:
                        tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                        headers = {"xi-api-key": elevenlabs_key, "Content-Type": "application/json"}
                        data = {
                            "text": ai_text, 
                            "model_id": "eleven_multilingual_v2", 
                            "voice_settings": {"stability": 0.4, "similarity_boost": 0.65}
                        }
                        tts_res = requests.post(tts_url, json=data, headers=headers)
                        if tts_res.status_code == 200:
                            ai_audio_bytes = tts_res.content

                    if has_nickname_audio and ai_audio_bytes:
                        nickname_bytes = get_nickname_audio_bytes(sel_role)
                        if nickname_bytes:
                            final_audio_bytes = merge_audio_clips(nickname_bytes, ai_audio_bytes)
                        else: final_audio_bytes = ai_audio_bytes
                    else: final_audio_bytes = ai_audio_bytes

                    if final_audio_bytes:
                        st.audio(final_audio_bytes, format="audio/mp3", autoplay=True)

            except Exception as e: st.error(f"Error: {e}")

        st.divider()
        st.markdown("##### ğŸ™ï¸ æŒ‰ä¸‹éŒ„éŸ³è·Ÿæˆ‘èªªè©±ï¼š")
        val = st.audio_input("éŒ„éŸ³", key="rec_pub")
        if val and persona_summary: process_chat(val)
        if st.session_state.chat_history:
            last = st.session_state.chat_history[-1]
            if last["role"] == "assistant":
                st.markdown(f'<div class="ai-bubble"><b>ç¥‚èªªï¼š</b><br>{last["content"]}</div>', unsafe_allow_html=True)

    st.divider()
    with st.expander("ğŸ”’ æœƒå“¡ç™»å…¥"):
        st.text_input("å¯†ç¢¼", type="password", key="pwd_input", on_change=check_pass)

else:
    # === ç®¡ç†å“¡å¾Œå° (Admin Mode) ===
    st.success("ğŸ”“ ç®¡ç†å“¡æ¨¡å¼")
    if st.button("ç™»å‡º"):
        st.session_state.is_admin = False
        st.rerun()

    # å„€è¡¨æ¿
    st.markdown("### ğŸ“Š ç³»çµ±å¥åº·å„€è¡¨æ¿")
    c_sys1, c_sys2 = st.columns(2)
    with c_sys1:
        st.markdown('<div class="dashboard-card">', unsafe_allow_html=True)
        st.caption("ğŸ—£ï¸ è²éŸ³åˆæˆé¡åº¦")
        used, limit = get_elevenlabs_usage()
        if limit > 0:
            st.progress(used / limit)
            st.write(f"**{used:,}** / {limit:,}")
        else: st.warning("ç„¡æ³•è®€å–")
        st.markdown('</div>', unsafe_allow_html=True)
    with c_sys2:
        st.markdown('<div class="dashboard-card">', unsafe_allow_html=True)
        st.caption("ğŸ§  å¤§è…¦é¤˜é¡")
        st.markdown("""<a href="https://platform.openai.com/settings/organization/billing/overview" target="_blank"><button style="width:100%;">ğŸ”— æŸ¥çœ‹å¸³å–®</button></a>""", unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ“ åŸºç¤äººè¨­", "ğŸ§  å›æ†¶è£œå®Œ", "ğŸ¯ å®Œç¾æš±ç¨±"])

    # TAB 1: åŸºç¤äººè¨­
    with tab1:
        st.caption("è¨­å®šå°è©±èªæ°£èˆ‡åŸºç¤è³‡è¨Š")
        c1, c2 = st.columns(2)
        with c1: t_role = st.selectbox("å°è±¡", list(ROLE_MAPPING.keys()), key="tr")
        with c2: member_name = st.text_input("æ‚¨çš„åå­— (ä¾›AIè­˜åˆ¥)", value="çˆ¸çˆ¸", key="mn")
        nickname = st.text_input("å°ˆå±¬æš±ç¨±", placeholder="ä¾‹å¦‚ï¼šå¯¶è²", key="nk")
        up_file = st.file_uploader(f"ä¸Šå‚³èˆ‡ã€{t_role}ã€‘çš„ç´€éŒ„", type="txt")
        if st.button("âœ¨ ç”ŸæˆåŸºç¤äººè¨­"):
            if up_file and member_name:
                with st.spinner("åˆ†æä¸­..."):
                    raw = up_file.read().decode("utf-8")
                    prompt = f"åˆ†æå°è©±ã€‚ä¸»è§’(æˆ‘):{member_name}ã€‚å°è±¡:{t_role}ã€‚æš±ç¨±:{nickname}ã€‚ç”ŸæˆSystem Promptï¼Œé‡é»ï¼šæ¨¡ä»¿ä¸»è§’èªæ°£ï¼Œå°è±¡æ˜¯{t_role}æ™‚å‹™å¿…ä½¿ç”¨æš±ç¨±{nickname}ã€‚è³‡æ–™ï¼š{raw[-20000:]}"
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    save_persona_summary(t_role, res.choices[0].message.content)
                    st.success("æ›´æ–°å®Œæˆ")

    # TAB 2: å›æ†¶è£œå®Œ (é›™æ¬„ + é€²åº¦æ¢)
    with tab2:
        # 1. æº–å‚™è³‡æ–™
        q_role = st.selectbox("è£œå……å°è±¡å›æ†¶", list(question_db.keys()), key="q_role")
        q_list = question_db.get(q_role, [])
        
        # å–å¾—å·²å›ç­”çš„æ­·å²
        memories = get_memories_by_role(q_role)
        answered_qs = set()
        for m in memories:
            if "ã€é—œæ–¼" in m['content'] and "ã€‘ï¼š" in m['content']:
                q_part = m['content'].split("ã€é—œæ–¼")[1].split("ã€‘ï¼š")[0]
                answered_qs.add(q_part)

        # ç‹€æ…‹ç®¡ç†
        if "edit_target" not in st.session_state: st.session_state.edit_target = None

        # æ±ºå®šç•¶å‰é¡Œç›®
        current_q = None
        if st.session_state.edit_target:
            current_q = st.session_state.edit_target
            st.info(f"âœï¸ æ­£åœ¨é‡æ–°éŒ„è£½ï¼š{current_q}")
        else:
            for q in q_list:
                if q not in answered_qs:
                    current_q = q
                    break
        
        # ã€é€²åº¦æ¢ - åŠŸèƒ½å›æ­¸ã€‘
        if len(q_list) > 0:
            progress = len(answered_qs) / len(q_list)
            st.progress(progress, text=f"å›æ†¶è£œå®Œé€²åº¦ï¼š{len(answered_qs)} / {len(q_list)}")

        # ä»‹é¢åˆ†æ¬„
        col_left, col_right = st.columns([1.5, 1], gap="medium")
        
        # --- å·¦æ¬„ï¼šæ“ä½œå€ ---
        with col_left:
            st.markdown("### ğŸ™ï¸ é€²è¡Œä¸­ä»»å‹™")
            if current_q:
                st.markdown(f"""
                <div class="question-card-active">
                    <div class="q-text">{current_q}</div>
                    <div style="font-size:14px; color:#555;">è«‹æŒ‰ä¸‹éŒ„éŸ³ï¼Œè‡ªç„¶åœ°è¬›è¿°é€™æ®µå›æ†¶...</div>
                </div>
                """, unsafe_allow_html=True)
                
                audio_ans = st.audio_input("éŒ„éŸ³å›ç­”", key=f"ans_{current_q}")
                
                if "transcribed_text" not in st.session_state: st.session_state.transcribed_text = ""
                
                if audio_ans:
                    trans = client.audio.transcriptions.create(model="whisper-1", file=audio_ans)
                    st.session_state.transcribed_text = trans.text
                    
                    st.text_area("ğŸ“ è­˜åˆ¥æ–‡å­— (å¯æ‰‹å‹•ä¿®æ”¹)", value=st.session_state.transcribed_text, key="edit_text_area")
                    
                    c_act1, c_act2 = st.columns(2)
                    with c_act1:
                        if st.button("ğŸ”Š è©¦è½ AI å”¸ä¸€é", use_container_width=True):
                            if st.session_state.transcribed_text:
                                with st.spinner("ç”Ÿæˆè©¦è½ä¸­..."):
                                    tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                                    headers = {"xi-api-key": elevenlabs_key, "Content-Type": "application/json"}
                                    data = {"text": st.session_state.transcribed_text, "model_id": "eleven_multilingual_v2", "voice_settings": {"stability": 0.4, "similarity_boost": 0.65}}
                                    r = requests.post(tts_url, json=data, headers=headers)
                                    if r.status_code == 200:
                                        st.audio(r.content, format="audio/mp3", autoplay=True)
                    
                    with c_act2:
                        if st.button("ğŸ’¾ ç¢ºèªç„¡èª¤ï¼Œå­˜å…¥ä¸¦è¨“ç·´", type="primary", use_container_width=True):
                            final_text = st.session_state.edit_text_area
                            with st.spinner("å­˜å…¥ä¸¦è¨“ç·´..."):
                                save_memory_fragment(q_role, current_q, final_text)
                                audio_ans.seek(0)
                                train_voice_sample(audio_ans.read())
                                st.success("å·²å„²å­˜ï¼")
                                st.session_state.edit_target = None
                                st.session_state.transcribed_text = ""
                                st.rerun()

                if st.button("â­ï¸ è·³éæ­¤é¡Œ"):
                    save_memory_fragment(q_role, current_q, "(å·²ç•¥é)")
                    st.rerun()
            else:
                st.success("ğŸ‰ å¤ªæ£’äº†ï¼æ­¤è§’è‰²çš„é¡Œåº«å·²å…¨éƒ¨å®Œæˆã€‚")

        # --- å³æ¬„ï¼šæ­·å²ç´€éŒ„ ---
        with col_right:
            st.markdown("### ğŸ“œ å›æ†¶å­˜æ‘º")
            st.caption("å·²å®Œæˆ (é»æ“Šé‡éŒ„)")
            with st.container(height=500):
                for mem in memories:
                    if "ã€é—œæ–¼" in mem['content']:
                        try:
                            q_part = mem['content'].split("ã€é—œæ–¼")[1].split("ã€‘ï¼š")[0]
                            a_part = mem['content'].split("ã€‘ï¼š")[1]
                            st.markdown(f"""
                            <div class="history-card">
                                <div class="history-q">Q: {q_part}</div>
                                <div class="history-a">A: {a_part[:30]}...</div>
                            </div>
                            """, unsafe_allow_html=True)
                            if st.button("ğŸ”„ é‡éŒ„", key=f"re_{mem['id']}"):
                                st.session_state.edit_target = q_part
                                st.rerun()
                        except: pass

    # TAB 3: å®Œç¾æš±ç¨±
    with tab3:
        st.subheader("ğŸ¯ å®Œç¾æš±ç¨±é‡ç¾")
        st.info("éŒ„è£½ä¸€æ®µçœŸå¯¦çš„å‘¼å–šï¼ŒAI æœƒåœ¨é–‹é ­ç›´æ¥æ’­æ”¾é€™æ®µéŒ„éŸ³ã€‚")
        nick_role = st.selectbox("éŒ„è£½çµ¦èª°è½ï¼Ÿ", list(ROLE_MAPPING.keys()), key="nick_role")
        st.markdown(f"è«‹æŒ‰ä¸‹éŒ„éŸ³ï¼Œå–Šä¸€è²çµ¦ã€{nick_role}ã€‘è½çš„æš±ç¨±ï¼š")
        real_nick_audio = st.audio_input("éŒ„è£½", key="real_nick_rec")
        if real_nick_audio:
            if st.button("ğŸ’¾ ä¸Šå‚³çœŸå¯¦è²éŸ³"):
                with st.spinner("è™•ç†ä¸­..."):
                    if upload_nickname_audio(nick_role, real_nick_audio.read()):
                        st.success("æˆåŠŸï¼")