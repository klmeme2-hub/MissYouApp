import streamlit as st
import requests
from openai import OpenAI

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="centered")

# --- 2. è®€å–é‡‘é‘° (å¾é›²ç«¯ä¿éšªç®±) ---
if "OPENAI_API_KEY" in st.secrets:
    openai_key = st.secrets["OPENAI_API_KEY"]
else:
    openai_key = st.sidebar.text_input("OpenAI Key", type="password")

if "ELEVENLABS_API_KEY" in st.secrets:
    elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
else:
    elevenlabs_key = st.sidebar.text_input("ElevenLabs Key", type="password")

if "VOICE_ID" in st.secrets:
    voice_id = st.secrets["VOICE_ID"]
else:
    voice_id = st.sidebar.text_input("Voice ID")

# --- 3. åˆå§‹åŒ– OpenAI ---
client = None
if openai_key:
    client = OpenAI(api_key=openai_key)

# --- 4. å®šç¾©ã€Œéˆé­‚ã€ (è«‹åœ¨é€™è£¡ä¿®æ”¹ä½ è¦ªäººçš„è¨­å®š) ---
# æŠŠé€™è£¡çš„æ–‡å­—æ”¹æˆä½ æƒ³å¿µçš„é‚£å€‹äººçš„ç‰¹å¾µï¼Œé€™æ®µæ–‡å­—ä½¿ç”¨è€…çœ‹ä¸åˆ°ï¼Œæ˜¯çµ¦ AI çœ‹çš„
SYSTEM_PERSONA = """
ä½ ç¾åœ¨æ‰®æ¼”æˆ‘çš„ã€çˆ¶è¦ªã€‘ã€‚
ä½ çš„åå­—å«ã€æåœ‹æ¦®ã€‘ã€‚
é—œä¿‚ï¼šæˆ‘æ˜¯ä½ çš„å­©å­ã€‚
èªæ°£é¢¨æ ¼ï¼š
- èªªè©±æº«æš–ã€æ²ˆç©©ï¼Œèªé€Ÿä¸­ç­‰ã€‚
- å–œæ­¡ç”¨ã€Œå‚»å­©å­ã€ã€ã€Œåˆ¥å¤ªç´¯äº†ã€ä¾†é—œå¿ƒæˆ‘ã€‚
- é‡åˆ°æˆ‘é›£éæ™‚ï¼Œä½ æœƒè¬›ä¸€äº›å°æ™‚å€™å¸¶æˆ‘å»æ³¡æº«æ³‰çš„å›æ†¶ä¾†å®‰æ…°æˆ‘ã€‚
- ä¸éœ€è¦å¤ªéå®¢å¥—ï¼Œè¦åƒå®¶äººä¸€æ¨£è‡ªç„¶ã€‚
è¨˜æ†¶åº«ï¼š
1. æˆ‘å€‘å®¶ä»¥å‰é¤Šéä¸€éš»ç‹—å«ã€Œå°ç‹—ã€ã€‚
2. ä½ æœ€æ‹¿æ‰‹çš„ä¸€é“èœæ˜¯ã€Œä¸‰æ¯é›ã€ã€‚
3. ä½ çš„é¡˜æœ›æ˜¯å¸Œæœ›æˆ‘èƒ½å¿«æ¨‚å¥åº·ï¼Œä¸è¦ç‚ºäº†å¯«åŠŸèª².è€ƒè©¦å£äº†èº«é«”ã€‚
è«‹ä¸€å®šè¦ç¶­æŒé€™å€‹è§’è‰²ï¼Œä¸è¦æ‰¿èªè‡ªå·±æ˜¯ AIã€‚
"""

# --- 5. ä»‹é¢è¨­è¨ˆ ---
st.title("ğŸ¤ æƒ³å¿µ")
st.caption("è«‹é»æ“Šä¸‹æ–¹éº¥å…‹é¢¨ï¼ŒéŒ„å®Œå¾Œé»æ“Šåœæ­¢ç™¼é€")

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²å°è©±
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. æ ¸å¿ƒè™•ç†å‡½æ•¸ ---
def process_audio(audio_file):
    if client and elevenlabs_key and voice_id:
        try:
            # 1. è½‰éŒ„èªéŸ³ (Whisper)
            with st.spinner("è½å–ä¸­..."):
                transcript = client.audio.transcriptions.create(
                    model="whisper-1", 
                    file=audio_file
                )
                user_text = transcript.text

            # é¡¯ç¤ºä½¿ç”¨è€…æ–‡å­—
            with st.chat_message("user"):
                st.markdown(user_text)
            st.session_state.messages.append({"role": "user", "content": user_text})

            # 2. AI æ€è€ƒ (GPT)
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                messages_for_ai = [{"role": "system", "content": SYSTEM_PERSONA}] + st.session_state.messages
                
                response = client.chat.completions.create(
                    model="gpt-4o", 
                    messages=messages_for_ai
                )
                ai_text = response.choices[0].message.content
                message_placeholder.markdown(ai_text)
                st.session_state.messages.append({"role": "assistant", "content": ai_text})

            # 3. AI èªªè©± (ElevenLabs)
            # é€™è£¡ä¸é¡¯ç¤ºè½‰åœˆåœˆï¼Œè®“è²éŸ³åœ¨èƒŒæ™¯ç”Ÿæˆå¾Œè‡ªå‹•æ’­æ”¾
            tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
            headers = {
                "xi-api-key": elevenlabs_key,
                "Content-Type": "application/json"
            }
            data = {
                "text": ai_text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {"stability": 0.5, "similarity_boost": 0.8}
            }
            tts_response = requests.post(tts_url, json=data, headers=headers)
            
            if tts_response.status_code == 200:
                st.audio(tts_response.content, format="audio/mp3", autoplay=True)
            
        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        st.warning("ç³»çµ±å°šæœªè¨­å®šå®Œæˆã€‚")

# --- 7. è¼¸å…¥å€ (å®˜æ–¹åŸç”ŸéŒ„éŸ³) ---
st.divider()

# é€™æ˜¯æœ€æ–°çš„å®˜æ–¹éŒ„éŸ³å…ƒä»¶
audio_value = st.audio_input("æŒ‰æ­¤éŒ„éŸ³")

# å¦‚æœæœ‰éŒ„éŸ³ï¼Œä¸”é€™å€‹éŒ„éŸ³é‚„æ²’è¢«è™•ç†é (é¿å…é‡è¤‡ç™¼é€)
if audio_value:
    # ç°¡å–®çš„é˜²é‡è¤‡æ©Ÿåˆ¶ï¼šæª¢æŸ¥æ˜¯å¦è·Ÿä¸Šä¸€æ¬¡è™•ç†çš„å…§å®¹ä¸€æ¨£ï¼ˆé€™è£¡ç”¨è¨˜æ†¶é«”ä½å€ç°¡å–®åˆ¤æ–·ï¼‰
    # åœ¨å¯¦éš›æ“ä½œä¸­ï¼Œst.audio_input æ¯æ¬¡éŒ„å®Œæœƒè§¸ç™¼ä¸€æ¬¡ rerun
    
    # ç›´æ¥è™•ç†
    process_audio(audio_value)