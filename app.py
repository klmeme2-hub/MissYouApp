import streamlit as st
import requests
from openai import OpenAI
from supabase import create_client, Client
import numpy as np
import os

# --- 1. é é¢èˆ‡ UI è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="centered")

# CSS å¼·åˆ¶ç¾åŒ– (é…åˆ config.toml é”åˆ°å®Œç¾æ•ˆæœ)
custom_css = """
<style>
    /* å¼·åˆ¶å­—é«”é¡è‰² */
    .stApp, p, h1, h2, h3, label, div, span { color: #333333 !important; }
    
    /* ä¸‹æ‹‰é¸å–®ä¿®å¾© */
    div[data-baseweb="select"] > div { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li:hover { background-color: #E3F2FD !important; }

    /* å°è©±æ°£æ³¡ */
    .ai-bubble {
        background-color: #FFFFFF;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        border-left: 5px solid #4A90E2;
        margin: 10px 0;
        color: #333333;
    }
    
    /* éš±è—é¸å–® */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- 2. åˆå§‹åŒ–èˆ‡é€£ç·š ---
# æª¢æŸ¥ Secrets
if "SUPABASE_URL" not in st.secrets or "ADMIN_PASSWORD" not in st.secrets:
    st.error("âš ï¸ è«‹å…ˆè¨­å®š Secrets")
    st.stop()

openai_key = st.secrets["OPENAI_API_KEY"]
elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
voice_id = st.secrets["VOICE_ID"]
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
admin_password = st.secrets["ADMIN_PASSWORD"]

client = OpenAI(api_key=openai_key)

@st.cache_resource
def init_supabase():
    return create_client(supabase_url, supabase_key)

supabase = init_supabase()

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

def get_embedding(text):
    """å°‡æ–‡å­—è½‰ç‚ºå‘é‡"""
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def save_memories_to_vector_db(role, text_data):
    """å°‡é•·ç¯‡å°è©±åˆ‡ç¢ä¸¦å­˜å…¥å‘é‡è³‡æ–™åº«"""
    supabase.table("memories").delete().eq("role", role).execute()
    
    chunk_size = 500
    overlap = 50
    chunks = []
    
    for i in range(0, len(text_data), chunk_size - overlap):
        chunk = text_data[i:i + chunk_size]
        if len(chunk) > 20:
            chunks.append(chunk)
            
    total_chunks = len(chunks)
    progress_bar = st.progress(0, text=f"æ­£åœ¨æ¤å…¥æ·±å±¤è¨˜æ†¶ (0/{total_chunks})...")
    
    for idx, chunk in enumerate(chunks):
        embedding = get_embedding(chunk)
        data = {
            "role": role,
            "content": chunk,
            "embedding": embedding
        }
        supabase.table("memories").insert(data).execute()
        progress_bar.progress((idx + 1) / total_chunks, text=f"æ­£åœ¨æ¤å…¥æ·±å±¤è¨˜æ†¶ ({idx+1}/{total_chunks})")
    
    progress_bar.empty()
    return True

def search_relevant_memories(role, query_text):
    """æœå°‹ç›¸é—œè¨˜æ†¶"""
    try:
        query_vec = get_embedding(query_text)
        response = supabase.rpc(
            "match_memories",
            {
                "query_embedding": query_vec,
                "match_threshold": 0.5,
                "match_count": 3,
                "search_role": role
            }
        ).execute()
        
        memory_text = "\n".join([item['content'] for item in response.data])
        return memory_text
    except Exception as e:
        print(f"æœå°‹å¤±æ•—: {e}")
        return ""

def save_persona_summary(role, content):
    data = {"role": role, "content": content}
    supabase.table("personas").upsert(data).execute()

def load_all_roles():
    try:
        res = supabase.table("personas").select("role").execute()
        return [i['role'] for i in res.data]
    except: return []

def load_persona(role):
    try:
        res = supabase.table("personas").select("content").eq("role", role).execute()
        return res.data[0]['content'] if res.data else None
    except: return None

# --- 4. æ¬Šé™ç®¡ç† ---
if "is_admin" not in st.session_state:
    st.session_state.is_admin = False

def check_pass():
    if st.session_state.pwd_input == admin_password:
        st.session_state.is_admin = True
        st.session_state.pwd_input = ""
    else:
        st.error("å¯†ç¢¼éŒ¯èª¤")

# --- 5. ä¸»ä»‹é¢ ---
st.title("ğŸ¤ æƒ³å¿µ")

if not st.session_state.is_admin:
    # === è¦ªå‹å‰å° ===
    roles = load_all_roles()
    if not roles:
        st.info("â˜ï¸ å°šæœªå»ºç«‹æ•¸ä½äººæ ¼")
    else:
        col_sel, col_pic = st.columns([2, 1])
        with col_sel:
            st.markdown("#### ğŸ‘‹ æ‚¨å¥½ï¼Œè«‹å•æ‚¨æ˜¯æˆ‘çš„...ï¼Ÿ")
            sel_role = st.selectbox("èº«åˆ†", roles, label_visibility="collapsed")
            persona_summary = load_persona(sel_role)
            if persona_summary: st.success(f"å·²é€£çµï¼š{sel_role}æ¨¡å¼")
        with col_pic:
            if os.path.exists("photo.jpg"): st.image("photo.jpg", use_container_width=True)

        if "chat_history" not in st.session_state: st.session_state.chat_history = []

        # --- æ ¸å¿ƒå°è©±å‡½æ•¸ (å·²ä¿®æ­£ç¸®æ’) ---
        def process_chat(audio_file):
            try:
                # 1. èªéŸ³è½‰å­—
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
                user_text = transcript.text

                # ã€é˜²å‘†ä¿®æ­£ã€‘ï¼šé€™è£¡ç¸®æ’å°é½Šäº†ï¼Œä¸æœƒå ±éŒ¯
                if not user_text or len(user_text.strip()) < 2:
                    st.warning("ğŸ‘‚ è½ä¸å¤ªæ¸…æ¥šï¼Œè«‹é è¿‘éº¥å…‹é¢¨å†èªªä¸€æ¬¡...")
                    return

                # 2. æœå°‹æ·±å±¤è¨˜æ†¶
                with st.spinner("å›æ†¶æª¢ç´¢ä¸­..."):
                    relevant_memory = search_relevant_memories(sel_role, user_text)
                
                # 3. çµ„åˆ Prompt
                system_instruction = f"""
                {persona_summary}
                
                ã€ç›¸é—œçš„å…·é«”å›æ†¶ç‰‡æ®µã€‘ï¼š
                {relevant_memory}
                
                è«‹æ ¹æ“šä¸Šè¿°çš„äººè¨­èˆ‡å›æ†¶ç‰‡æ®µä¾†å›ç­”ã€‚å¦‚æœå›æ†¶ç‰‡æ®µä¸­æœ‰å…·é«”ç´°ç¯€ï¼Œè«‹è‡ªç„¶åœ°å¸¶å…¥å°è©±ä¸­ã€‚
                """
                
                recent_history = st.session_state.chat_history[-6:] 
                msgs = [{"role": "system", "content": system_instruction}] + recent_history
                msgs.append({"role": "user", "content": user_text})

                # 4. AI ç”Ÿæˆ
                res = client.chat.completions.create(model="gpt-4o-mini", messages=msgs)
                ai_text = res.choices[0].message.content

                st.session_state.chat_history.append({"role": "user", "content": user_text})
                st.session_state.chat_history.append({"role": "assistant", "content": ai_text})

                # 5. èªéŸ³åˆæˆ
                tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                headers = {"xi-api-key": elevenl