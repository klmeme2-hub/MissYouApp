import streamlit as st
import json
from openai import OpenAI
import requests

# å¼•å…¥æˆ‘å€‘æ‹†åˆ†å¥½çš„æ¨¡çµ„
from modules import ui, auth, database, audio
from modules.config import ROLE_MAPPING

# 1. è¼‰å…¥ UI è¨­å®š
st.set_page_config(page_title="æƒ³å¿µ - éˆé­‚åˆ»éŒ„å®¤", page_icon="ğŸ¤", layout="wide")
ui.load_css()

# 2. åˆå§‹åŒ–ç³»çµ±
if "SUPABASE_URL" not in st.secrets:
    st.error("âš ï¸ è«‹å…ˆè¨­å®š Secrets")
    st.stop()

supabase = database.init_supabase()
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# 3. è®€å–é¡Œåº«
@st.cache_data
def load_questions():
    try:
        with open('questions.json', 'r', encoding='utf-8') as f: return json.load(f)
    except: return {}
question_db = load_questions()

# 4. ç‹€æ…‹ç®¡ç†
if "user" not in st.session_state: st.session_state.user = None
if "guest_data" not in st.session_state: st.session_state.guest_data = None
if "step" not in st.session_state: st.session_state.step = 1

# ==========================================
# ä¸»ç¨‹å¼é‚è¼¯è·¯ç”±
# ==========================================

# æƒ…å¢ƒ A: è¨ªå®¢æ¨¡å¼ (è¦ªå‹å·²è¼¸å…¥ Token)
if st.session_state.guest_data:
    owner_data = st.session_state.guest_data
    role_name = owner_data['role']
    st.markdown(f"<h2 style='text-align:center;'>ğŸ“ èˆ‡ [{role_name}] é€šè©±ä¸­...</h2>", unsafe_allow_html=True)
    
    persona_summary = database.load_persona(supabase, role_name)
    if not persona_summary:
        st.warning("å°æ–¹å°šæœªè¨­å®šæ­¤è§’è‰²çš„éˆé­‚è³‡æ–™ã€‚")
    else:
        col_c1, col_c2 = st.columns([1, 2])
        with col_c1: st.image("https://cdn-icons-png.flaticon.com/512/607/607414.png", width=150)
        with col_c2: st.info(f"é€™æ˜¯ {role_name} ç•™çµ¦æ‚¨çš„è²éŸ³ã€‚")

        if "chat_history" not in st.session_state: st.session_state.chat_history = []
        
        audio_val = st.audio_input("è«‹æŒ‰æ­¤èªªè©±...", key="guest_rec")
        if audio_val:
            try:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_val)
                user_text = transcript.text
                if len(user_text.strip()) > 1:
                    with st.spinner("..."):
                        mem = database.search_relevant_memories(supabase, role_name, user_text)
                        has_nick = audio.get_nickname_audio_bytes(supabase, role_name) is not None
                        nick_instr = "ã€æŒ‡ä»¤ã€‘å›æ‡‰é–‹é ­ä¸è¦åŒ…å«æš±ç¨±ã€‚" if has_nick else "è«‹åœ¨é–‹é ­å‘¼å–šæš±ç¨±ã€‚"
                        prompt = f"{persona_summary}\nã€å›æ†¶ã€‘{mem}\n{nick_instr}\nèªæ°£è‡ªç„¶ã€‚"
                        
                        msgs = [{"role": "system", "content": prompt}] + st.session_state.chat_history[-4:]
                        msgs.append({"role": "user", "content": user_text})
                        
                        res = client.chat.completions.create(model="gpt-4o-mini", messages=msgs)
                        ai_text = res.choices[0].message.content
                        
                        st.session_state.chat_history.append({"role": "user", "content": user_text})
                        st.session_state.chat_history.append({"role": "assistant", "content": ai_text})
                        
                        # TTS
                        tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{st.secrets['VOICE_ID']}"
                        headers = {"xi-api-key": st.secrets['ELEVENLABS_API_KEY'], "Content-Type": "application/json"}
                        data = {"text": ai_text, "model_id": "eleven_multilingual_v2", "voice_settings": {"stability": 0.4, "similarity_boost": 0.65}}
                        tts_res = requests.post(tts_url, json=data, headers=headers)
                        
                        final_audio = tts_res.content
                        if has_nick:
                            nick_bytes = audio.get_nickname_audio_bytes(supabase, role_name)
                            if nick_bytes: final_audio = audio.merge_audio_clips(nick_bytes, final_audio)
                        
                        st.audio(final_audio, format="audio/mp3", autoplay=True)
                        st.markdown(f'<div class="ai-bubble">{ai_text}</div>', unsafe_allow_html=True)
            except Exception as e: st.error("é€£ç·šä¸ç©©")

    st.divider()
    if st.button("é›¢é–‹é€šè©±"):
        st.session_state.guest_data = None
        st.rerun()

# æƒ…å¢ƒ B: æœªç™»å…¥ (é¦–é )
elif not st.session_state.user:
    col1, col2 = st.columns([1, 1])
    with col1:
        st.markdown("## ğŸ‘‹ æˆ‘æ˜¯è¦ªå‹")
        token_input = st.text_input("é€šè¡Œç¢¼ (Token)", placeholder="ä¾‹å¦‚ï¼šA8K29", label_visibility="collapsed")
        if st.button("é–‹å§‹å°è©±", type="primary", use_container_width=True):
            data = database.validate_token(supabase, token_input.strip())
            if data:
                st.session_state.guest_data = {'owner_id': data['user_id'], 'role': data['role']}
                st.success("é©—è­‰æˆåŠŸï¼")
                st.rerun()
            else: st.error("ç„¡æ•ˆçš„é€šè¡Œç¢¼")

    with col2:
        st.markdown("## ğŸ‘¤ æˆ‘æ˜¯æœƒå“¡")
        tab_l, tab_s = st.tabs(["ç™»å…¥", "è¨»å†Š"])
        with tab_l:
            email = st.text_input("Email", key="l_e")
            pwd = st.text_input("å¯†ç¢¼", type="password", key="l_p")
            if st.button("ç™»å…¥", use_container_width=True):
                res = auth.login_user(supabase, email, pwd)
                if res and res.user: 
                    st.session_state.user = res
                    st.rerun()
                else: st.error("éŒ¯èª¤")
        with tab_s:
            s_email = st.text_input("Email", key="s_e")
            s_pwd = st.text_input("è¨­å®šå¯†ç¢¼", type="password", key="s_p")
            if st.button("è¨»å†Š", use_container_width=True):
                res = auth.signup_user(supabase, s_email, s_pwd)
                if res and res.user:
                    st.success("æˆåŠŸï¼")
                    st.session_state.user = res
                    st.rerun()
                else: st.error("å¤±æ•—")

# æƒ…å¢ƒ C: æœƒå“¡å¾Œå°
else:
    with st.sidebar:
        st.write(f"ğŸ‘¤ {st.session_state.user.user.email}")
        if st.button("ç™»å‡º"):
            supabase.auth.sign_out()
            st.session_state.user = None
            st.rerun()

    st.title("ğŸ™ï¸ éˆé­‚åˆ»éŒ„å®¤")
    col_r1, col_r2 = st.columns([3, 1])
    with col_r1: target_role = st.selectbox("æ‚¨æƒ³è¦å°‡ä½ çš„è²éŸ³ç•™çµ¦èª°?", list(ROLE_MAPPING.keys()))
    
    tab1, tab2, tab3 = st.tabs(["ğŸ§¬ è¤‡è£½è²ç´‹ (æ­¥é©Ÿå¼•å°)", "ğŸ“ äººè¨­è£œå®Œ", "ğŸ§  å›æ†¶è£œå®Œ"])

    # TAB 1: è¤‡è£½è²ç´‹
    with tab1:
        cols = st.columns(5)
        steps = ["â¶ å–šå", "â· å®‰æ…°", "â¸ é¼“å‹µ", "â¹ è©¼è«§", "âº å®Œæˆ"]
        for i, s in enumerate(steps):
            if i + 1 == st.session_state.step: cols[i].markdown(f"**<span style='color:#1565C0'>{s}</span>**", unsafe_allow_html=True)
            else: cols[i].markdown(f"<span style='color:#ccc'>{s}</span>", unsafe_allow_html=True)
        st.markdown("---")

        if st.session_state.step == 1:
            st.subheader("STEP 1: è¼•è¼•å–šä½ çš„å")
            st.info("è«‹éŒ„ä¸‹æ‚¨å¹³å¸¸å‘¼å–šå°æ–¹æš±ç¨±çš„è²éŸ³ï¼Œé€™å°‡æˆç‚ºæ¯æ¬¡å°è©±çš„é–‹é ­ã€‚")
            nickname_text = st.text_input("è«‹è¼¸å…¥æš±ç¨±æ–‡å­—", placeholder="ä¾‹å¦‚ï¼šè€å©†ï½")
            rec = st.audio_input("éŒ„éŸ³ (å»ºè­° 2-3 ç§’)")
            if rec and nickname_text:
                if st.button("ğŸ’¾ ä¸Šå‚³ä¸¦è©¦è½"):
                    with st.spinner("è™•ç†ä¸­..."):
                        audio_bytes = rec.read()
                        audio.upload_nickname_audio(supabase, target_role, audio_bytes)
                        rec.seek(0)
                        audio.train_voice_sample(rec.read())
                        
                        tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{st.secrets['VOICE_ID']}"
                        headers = {"xi-api-key": st.secrets['ELEVENLABS_API_KEY'], "Content-Type": "application/json"}
                        data = {"text": "æœ€è¿‘å¥½å—ï¼Ÿ", "model_id": "eleven_multilingual_v2"}
                        r = requests.post(tts_url, json=data, headers=headers)
                        
                        final = audio.merge_audio_clips(audio_bytes, r.content)
                        st.audio(final, format="audio/mp3")
                        st.success("è²ç´‹å·²å»ºç«‹ï¼")
            if st.button("ä¸‹ä¸€æ­¥ â†’"): st.session_state.step = 2; st.rerun()

        elif st.session_state.step in [2, 3, 4]:
            # (é€™è£¡æ”¾è…³æœ¬é‚è¼¯ï¼Œç‚ºç¯€çœç¯‡å¹…çœç•¥ï¼Œè«‹ç›´æ¥è¤‡è£½ä¸Šä¸€ç‰ˆä»£ç¢¼çš„è…³æœ¬éƒ¨åˆ†å³å¯ï¼Œåªéœ€è¨˜å¾—å‘¼å« audio.train_voice_sample)
            scripts = {2: ("åˆ»éŒ„ã€Œå®‰æ…°èªæ°£ã€", "è…³æœ¬å…§å®¹..."), 3: ("åˆ»éŒ„ã€Œé¼“å‹µèªæ°£ã€", "è…³æœ¬å…§å®¹..."), 4: ("åˆ»éŒ„ã€Œè¼•é¬†è©¼è«§èªæ°£ã€", "è…³æœ¬å…§å®¹...")} # è«‹å¡«å…¥å®Œæ•´å…§å®¹
            # ... (é€™è£¡é‚è¼¯èˆ‡ä¸Šä¸€ç‰ˆç›¸åŒï¼Œåªæ˜¯å‡½æ•¸æ”¹ç‚ºå‘¼å« module)
            # ç¯„ä¾‹ï¼š audio.train_voice_sample(rec.read())
            pass # è«‹å¡«å…¥å®Œæ•´é‚è¼¯
            
        elif st.session_state.step == 5:
            st.balloons()
            st.success("ğŸ‰ åˆ»éŒ„å®Œæˆï¼")
            if "share_token" not in st.session_state:
                st.session_state.share_token = database.create_share_token(supabase, target_role)
            token = st.session_state.share_token
            st.markdown(f"### æ‚¨çš„å°ˆå±¬åˆ†äº«ç¢¼ï¼š`{token}`")
            if st.button("â† è¿”å›"): st.session_state.step = 1; st.rerun()

    # TAB 2 & 3: ä½¿ç”¨ database æ¨¡çµ„çš„å‡½æ•¸å³å¯
    # ... (è«‹å°‡ä¸Šä¸€ç‰ˆçš„ TAB 2 å’Œ TAB 3 é‚è¼¯è¤‡è£½éä¾†ï¼Œä¸¦å°‡ save_memory_fragment ç­‰å‡½æ•¸æ”¹ç‚º database.save_memory_fragment)