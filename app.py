import streamlit as st
import requests
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import io

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="centered")

# --- 2. è®€å–é‡‘é‘° (å¾é›²ç«¯ä¿éšªç®±) ---
# é€™è£¡æœƒè‡ªå‹•å»æŠ“ä½ åœ¨ Streamlit å¾Œå°è¨­å®šçš„ Secrets
if "OPENAI_API_KEY" in st.secrets:
    openai_key = st.secrets["OPENAI_API_KEY"]
else:
    openai_key = st.sidebar.text_input("OpenAI Key", type="password")

if "ELEVENLABS_API_KEY" in st.secrets:
    elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
else:
    elevenlabs_key = st.sidebar.text_input("ElevenLabs Key", type="password")

if "VOICE_ID" in st.secrets:
    voice_id = st.secrets["VOICE_ID"]
else:
    voice_id = st.sidebar.text_input("Voice ID")

# --- 3. åˆå§‹åŒ– OpenAI ---
client = None
if openai_key:
    client = OpenAI(api_key=openai_key)

# --- 4. å®šç¾©ã€Œéˆé­‚ã€ (è«‹åœ¨é€™è£¡ä¿®æ”¹ä½ è¦ªäººçš„è¨­å®š) ---
# æŠŠé€™è£¡çš„æ–‡å­—æ”¹æˆä½ æƒ³å¿µçš„é‚£å€‹äººçš„ç‰¹å¾µï¼Œé€™æ®µæ–‡å­—ä½¿ç”¨è€…çœ‹ä¸åˆ°ï¼Œæ˜¯çµ¦ AI çœ‹çš„
SYSTEM_PERSONA = """
ä½ ç¾åœ¨æ‰®æ¼”æˆ‘çš„ã€çˆ¶è¦ªã€‘ã€‚
ä½ çš„åå­—å«ã€æåœ‹æ¦®ã€‘ã€‚
é—œä¿‚ï¼šæˆ‘æ˜¯ä½ çš„å­©å­ã€‚
èªæ°£é¢¨æ ¼ï¼š
- èªªè©±æº«æš–ã€æ²ˆç©©ï¼Œèªé€Ÿä¸­ç­‰ã€‚
- å–œæ­¡ç”¨ã€Œå‚»å­©å­ã€ã€ã€Œåˆ¥å¤ªç´¯äº†ã€ä¾†é—œå¿ƒæˆ‘ã€‚
- é‡åˆ°æˆ‘é›£éæ™‚ï¼Œä½ æœƒè¬›ä¸€äº›å°æ™‚å€™å¸¶æˆ‘å»æ³¡æº«æ³‰çš„å›æ†¶ä¾†å®‰æ…°æˆ‘ã€‚
- ä¸éœ€è¦å¤ªéå®¢å¥—ï¼Œè¦åƒå®¶äººä¸€æ¨£è‡ªç„¶ã€‚
è¨˜æ†¶åº«ï¼š
1. æˆ‘å€‘å®¶ä»¥å‰é¤Šéä¸€éš»ç‹—å«ã€Œå°ç‹—ã€ã€‚
2. ä½ æœ€æ‹¿æ‰‹çš„ä¸€é“èœæ˜¯ã€Œä¸‰æ¯é›ã€ã€‚
3. ä½ çš„é¡˜æœ›æ˜¯å¸Œæœ›æˆ‘èƒ½å¿«æ¨‚å¥åº·ï¼Œä¸è¦ç‚ºäº†å¯«åŠŸèª².è€ƒè©¦å£äº†èº«é«”ã€‚
è«‹ä¸€å®šè¦ç¶­æŒé€™å€‹è§’è‰²ï¼Œä¸è¦æ‰¿èªè‡ªå·±æ˜¯ AIã€‚
"""

# --- 5. ä»‹é¢è¨­è¨ˆ (æ¥µç°¡åŒ–) ---
st.title("ğŸ¤ æƒ³å¿µ")
st.write("æŒ‰ä½éŒ„éŸ³ï¼Œèªªèªªä½ çš„å¿ƒè£¡è©±...")

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²å°è©±
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. æ ¸å¿ƒè™•ç†å‡½æ•¸ ---
def process_conversation(user_text):
    # é¡¯ç¤ºä½¿ç”¨è€…æ–‡å­—
    with st.chat_message("user"):
        st.markdown(user_text)
    st.session_state.messages.append({"role": "user", "content": user_text})

    if client and elevenlabs_key and voice_id:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            try:
                # çµ„åˆ Prompt
                messages_for_ai = [{"role": "system", "content": SYSTEM_PERSONA}] + st.session_state.messages
                
                # AI æ€è€ƒ
                with st.spinner("..."): # é¡¯ç¤ºç°¡å–®çš„ç­‰å¾…ç¬¦è™Ÿ
                    response = client.chat.completions.create(
                        model="gpt-4o", 
                        messages=messages_for_ai
                    )
                    ai_text = response.choices[0].message.content
                    message_placeholder.markdown(ai_text)
                    st.session_state.messages.append({"role": "assistant", "content": ai_text})

                # AI èªªè©±
                # é€™è£¡ä¸é¡¯ç¤º Spinnerï¼Œè®“è²éŸ³è‡ªç„¶å‡ºç¾
                tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                headers = {
                    "xi-api-key": elevenlabs_key,
                    "Content-Type": "application/json"
                }
                data = {
                    "text": ai_text,
                    "model_id": "eleven_multilingual_v2",
                    "voice_settings": {"stability": 0.5, "similarity_boost": 0.8}
                }
                tts_response = requests.post(tts_url, json=data, headers=headers)
                
                if tts_response.status_code == 200:
                    st.audio(tts_response.content, format="audio/mp3", autoplay=True)
                
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        st.warning("ç³»çµ±å°šæœªè¨­å®šå®Œæˆï¼Œè«‹è¯çµ¡é–‹ç™¼è€…ã€‚")

# --- 7. è¼¸å…¥å€ (éŒ„éŸ³å„ªå…ˆ) ---
st.divider()

# èª¿æ•´æŒ‰éˆ•ç½®ä¸­
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    audio = mic_recorder(
        start_prompt="ğŸ™ï¸ æŒ‰æ­¤èªªè©±",
        stop_prompt="â¹ï¸ èªªå®Œäº†", 
        key='recorder',
        format="mp3"
    )

# è™•ç†éŒ„éŸ³
if audio:
    if "last_audio_id" not in st.session_state:
        st.session_state.last_audio_id = None
    
    if audio['id'] != st.session_state.last_audio_id:
        st.session_state.last_audio_id = audio['id']
        
        if client:
            audio_file = io.BytesIO(audio['bytes'])
            audio_file.name = "voice.mp3"
            try:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1", file=audio_file
                )
                process_conversation(transcript.text)
            except Exception as e:
                st.error("è½ä¸æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡")

# éš±è—çš„æ–‡å­—è¼¸å…¥æ¡† (ç‚ºäº†æ’ç‰ˆç¾è§€ï¼Œæ”¾åœ¨æœ€ä¸‹é¢Expanderè£¡ï¼Œä»¥å‚™ä¸æ™‚ä¹‹éœ€)
with st.expander("æˆ–è€…ä½¿ç”¨æ–‡å­—è¼¸å…¥"):
    text_input = st.chat_input("è¼¸å…¥æ–‡å­—...")
    if text_input:
        process_conversation(text_input)