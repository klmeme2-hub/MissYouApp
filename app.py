import streamlit as st
import requests
from openai import OpenAI
from supabase import create_client, Client
import numpy as np
import os
import json

# --- 1. é é¢èˆ‡ UI è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="centered")

custom_css = """
<style>
    .stApp, p, h1, h2, h3, label, div, span { color: #333333 !important; }
    div[data-baseweb="select"] > div { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li:hover { background-color: #E3F2FD !important; }
    .ai-bubble {
        background-color: #FFFFFF;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        border-left: 5px solid #4A90E2;
        margin: 10px 0;
        color: #333333;
    }
    .question-card {
        background-color: #E3F2FD;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 15px;
        border: 1px solid #BBDEFB;
    }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- 2. åˆå§‹åŒ– ---
if "SUPABASE_URL" not in st.secrets or "ADMIN_PASSWORD" not in st.secrets:
    st.error("âš ï¸ è«‹å…ˆè¨­å®š Secrets")
    st.stop()

openai_key = st.secrets["OPENAI_API_KEY"]
elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
voice_id = st.secrets["VOICE_ID"]
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
admin_password = st.secrets["ADMIN_PASSWORD"]

client = OpenAI(api_key=openai_key)

@st.cache_resource
def init_supabase():
    return create_client(supabase_url, supabase_key)

supabase = init_supabase()

# --- 3. å…§å»ºé¡Œåº« (å¼•å°æœƒå“¡è¼¸å…¥) ---
INTERVIEW_QUESTIONS = {
    "å¦»å­": [
        "å¥¹çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿä½ å€‘é€šå¸¸æ€éº¼æ…¶ç¥ï¼Ÿ",
        "ä½ å€‘çš„çµå©šç´€å¿µæ—¥æ˜¯ä½•æ™‚ï¼Ÿç•¶æ™‚æ±‚å©šçš„å ´æ™¯æ˜¯ä»€éº¼ï¼Ÿ",
        "å¥¹æœ€å–œæ­¡çš„é¡è‰²ã€èŠ±æœµæˆ–é£Ÿç‰©æ˜¯ä»€éº¼ï¼Ÿ",
        "å¥¹æœ‰æ²’æœ‰ä»€éº¼å£é ­ç¦ªæˆ–æ˜¯å¯æ„›çš„å°ç¿’æ…£ï¼Ÿ",
        "ä½ å€‘æœ€é›£å¿˜çš„ä¸€æ¬¡æ—…è¡Œæ˜¯å»å“ªè£¡ï¼Ÿç™¼ç”Ÿäº†ä»€éº¼äº‹ï¼Ÿ",
        "ä½ å¹³å¸¸éƒ½æ€éº¼ç¨±å‘¼å¥¹ï¼Ÿ(ä¾‹å¦‚ï¼šè€å©†ã€å¯¶è²ã€å…¨åï¼Ÿ)",
        "å®¶è£¡æœ‰å¯µç‰©å—ï¼Ÿåå­—å«ä»€éº¼ï¼Ÿå¥¹è·Ÿå¯µç‰©çš„é—œä¿‚å¦‚ä½•ï¼Ÿ",
        "å¦‚æœå¥¹é›£éæ™‚ï¼Œä½ é€šå¸¸æœƒæ€éº¼å®‰æ…°å¥¹ï¼Ÿ"
    ],
    "ä¸ˆå¤«": [
        "ä»–çš„èˆˆè¶£æ˜¯ä»€éº¼ï¼Ÿ(é‡£é­šã€æ‰“çƒã€éŠæˆ²ï¼Ÿ)",
        "ä»–æœ€æ„›åƒçš„ä¸€é“èœæ˜¯ä»€éº¼ï¼Ÿ",
        "ä½ å€‘ä¹‹é–“æœ‰æ²’æœ‰ä»€éº¼åªæœ‰å…©äººæ‰æ‡‚çš„ç¬‘è©±ï¼Ÿ",
        "ä»–å¹³å¸¸æ€éº¼ç¨±å‘¼å¦³ï¼Ÿ"
    ],
    "å…’å¥³": [
        "å­©å­çš„å°åæ˜¯ä»€éº¼ï¼Ÿç‚ºä»€éº¼å–é€™å€‹åå­—ï¼Ÿ",
        "ä»–/å¥¹å¹¾æ­²äº†ï¼Ÿç¾åœ¨æ­£åœ¨è®€æ›¸é‚„æ˜¯å·¥ä½œï¼Ÿ",
        "ä½ å°ä»–/å¥¹æœ€å¤§çš„æœŸæœ›æ˜¯ä»€éº¼ï¼Ÿ",
        "å°æ™‚å€™æœ‰æ²’æœ‰ç™¼ç”Ÿéä»€éº¼è®“ä½ å°è±¡æ·±åˆ»çš„ç³—äº‹ï¼Ÿ",
        "å¦‚æœä»–/å¥¹é‡åˆ°æŒ«æŠ˜ï¼Œä½ é€šå¸¸æœƒè·Ÿä»–èªªä»€éº¼ï¼Ÿ"
    ],
    "æœ‹å‹": [
        "ä½ å€‘æ˜¯æ€éº¼èªè­˜çš„ï¼Ÿèªè­˜å¤šä¹…äº†ï¼Ÿ",
        "ä½ å€‘ä»¥å‰æœ€å¸¸ä¸€èµ·åšä»€éº¼è ¢äº‹ï¼Ÿ",
        "ä»–æœ‰ä»€éº¼ç¶½è™Ÿï¼Ÿ"
    ]
}

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

def get_embedding(text):
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def save_memory_fragment(role, text_content):
    """å„²å­˜å–®æ¢è¨˜æ†¶ç‰‡æ®µ (ç”¨æ–¼å›ç­”å•å·)"""
    embedding = get_embedding(text_content)
    data = {
        "role": role,
        "content": text_content,
        "embedding": embedding
    }
    supabase.table("memories").insert(data).execute()
    return True

def search_relevant_memories(role, query_text):
    try:
        query_vec = get_embedding(query_text)
        response = supabase.rpc(
            "match_memories",
            {"query_embedding": query_vec, "match_threshold": 0.5, "match_count": 3, "search_role": role}
        ).execute()
        return "\n".join([item['content'] for item in response.data])
    except: return ""

def save_persona_summary(role, content):
    data = {"role": role, "content": content}
    supabase.table("personas").upsert(data).execute()

def load_all_roles():
    try:
        res = supabase.table("personas").select("role").execute()
        return [i['role'] for i in res.data]
    except: return []

def load_persona(role):
    try:
        res = supabase.table("personas").select("content").eq("role", role).execute()
        return res.data[0]['content'] if res.data else None
    except: return None

# --- æ–°å¢åŠŸèƒ½ï¼šä¸Šå‚³éŒ„éŸ³åˆ° ElevenLabs é€²è¡Œè¨“ç·´ ---
def train_voice_sample(audio_bytes):
    """å°‡éŒ„éŸ³æª”å‚³é€çµ¦ ElevenLabs å¢åŠ è¨“ç·´æ•¸æ“š"""
    try:
        url = f"https://api.elevenlabs.io/v1/voices/{voice_id}/edit"
        headers = {"xi-api-key": elevenlabs_key}
        
        # æº–å‚™æª”æ¡ˆ
        files = {
            'files': ('training_sample.mp3', audio_bytes, 'audio/mpeg')
        }
        # é€™è£¡ä¸æ”¹è®Šåå­—ï¼Œåªä¸Šå‚³æª”æ¡ˆ
        data = {'name': 'My Digital Clone'} 
        
        response = requests.post(url, headers=headers, data=data, files=files)
        return response.status_code == 200
    except Exception as e:
        st.error(f"ä¸Šå‚³å¤±æ•—: {e}")
        return False

# --- 5. æ¬Šé™ç®¡ç† ---
if "is_admin" not in st.session_state: st.session_state.is_admin = False

def check_pass():
    if st.session_state.pwd_input == admin_password:
        st.session_state.is_admin = True
        st.session_state.pwd_input = ""
    else: st.error("å¯†ç¢¼éŒ¯èª¤")

# --- 6. ä¸»ä»‹é¢ ---
st.title("ğŸ¤ æƒ³å¿µ")

if not st.session_state.is_admin:
    # === è¦ªå‹å‰å° ===
    roles = load_all_roles()
    if not roles:
        st.info("â˜ï¸ å°šæœªå»ºç«‹æ•¸ä½äººæ ¼")
    else:
        col_sel, col_pic = st.columns([2, 1])
        with col_sel:
            st.markdown("#### ğŸ‘‹ æ‚¨å¥½ï¼Œè«‹å•æ‚¨æ˜¯æˆ‘çš„...ï¼Ÿ")
            sel_role = st.selectbox("èº«åˆ†", roles, label_visibility="collapsed")
            persona_summary = load_persona(sel_role)
            if persona_summary: st.success(f"å·²é€£çµï¼š{sel_role}æ¨¡å¼")
        with col_pic:
            if os.path.exists("photo.jpg"): st.image("photo.jpg", use_container_width=True)

        if "chat_history" not in st.session_state: st.session_state.chat_history = []

        def process_chat(audio_file):
            try:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
                user_text = transcript.text
                if not user_text or len(user_text.strip()) < 2:
                    st.warning("ğŸ‘‚ è«‹å†èªªä¸€æ¬¡..."); return

                with st.spinner("å›æ†¶æª¢ç´¢ä¸­..."):
                    relevant_memory = search_relevant_memories(sel_role, user_text)
                
                system_instruction = f"""
                {persona_summary}
                ã€ç›¸é—œçš„æ·±å±¤è¨˜æ†¶ã€‘ï¼š{relevant_memory}
                è«‹å‹™å¿…ä½¿ç”¨æˆ‘å°ã€{sel_role}ã€‘çš„å°ˆå±¬ç¨±å‘¼ï¼ˆä¾‹å¦‚å°åï¼‰ã€‚èªæ°£è¦è‡ªç„¶ï¼ŒåŒ…å«å‘¼å¸æ„Ÿã€‚
                """
                recent_history = st.session_state.chat_history[-6:] 
                msgs = [{"role": "system", "content": system_instruction}] + recent_history
                msgs.append({"role": "user", "content": user_text})

                res = client.chat.completions.create(model="gpt-4o-mini", messages=msgs)
                ai_text = res.choices[0].message.content

                st.session_state.chat_history.append({"role": "user", "content": user_text})
                st.session_state.chat_history.append({"role": "assistant", "content": ai_text})

                # è²éŸ³åƒæ•¸å„ªåŒ– (æ›´æ„Ÿæ€§)
                tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                headers = {"xi-api-key": elevenlabs_key, "Content-Type": "application/json"}
                data = {
                    "text": ai_text, 
                    "model_id": "eleven_multilingual_v2", 
                    "voice_settings": {"stability": 0.4, "similarity_boost": 0.65} # åƒæ•¸å„ªåŒ–
                }
                tts_res = requests.post(tts_url, json=data, headers=headers)
                if tts_res.status_code == 200:
                    st.audio(tts_res.content, format="audio/mp3", autoplay=True)
            except Exception as e: st.error(f"Error: {e}")

        st.divider()
        st.markdown("##### ğŸ™ï¸ æŒ‰ä¸‹éŒ„éŸ³è·Ÿæˆ‘èªªè©±ï¼š")
        val = st.audio_input("éŒ„éŸ³", key="rec_pub")
        if val and persona_summary: process_chat(val)
        if st.session_state.chat_history:
            last = st.session_state.chat_history[-1]
            if last["role"] == "assistant":
                st.markdown(f'<div class="ai-bubble"><b>ç¥‚èªªï¼š</b><br>{last["content"]}</div>', unsafe_allow_html=True)

    st.divider()
    with st.expander("ğŸ”’ æœƒå“¡ç™»å…¥"):
        st.text_input("å¯†ç¢¼", type="password", key="pwd_input", on_change=check_pass)

else:
    # === ç®¡ç†å“¡å¾Œå° (ä¸‰å¤§åŠŸèƒ½å€) ===
    st.success("ğŸ”“ ç®¡ç†å“¡æ¨¡å¼")
    if st.button("ç™»å‡º"):
        st.session_state.is_admin = False
        st.rerun()

    tab1, tab2, tab3 = st.tabs(["ğŸ“ åŸºç¤äººè¨­ (æª”æ¡ˆ)", "ğŸ§  å›æ†¶è£œå®Œ (è¨ªè«‡)", "ğŸ™ï¸ è²éŸ³ç‰¹è¨“ (éŒ„éŸ³)"])

    # --- TAB 1: åŸºç¤æª”æ¡ˆä¸Šå‚³ (åŸæœ‰åŠŸèƒ½) ---
    with tab1:
        st.caption("ä¸€æ¬¡æ€§ä¸Šå‚³å¤§é‡å°è©±ç´€éŒ„")
        c1, c2 = st.columns(2)
        with c1: t_role = st.selectbox("å°è±¡", ["å¦»å­", "ä¸ˆå¤«", "å…’å­", "å¥³å…’", "æœ‹å‹"], key="tr")
        with c2: nickname = st.text_input("æ‚¨å°ä»–/å¥¹çš„å°ˆå±¬æš±ç¨±", placeholder="ä¾‹å¦‚ï¼šå¯¶è²ã€å°èƒ–", key="nk")
        
        up_file = st.file_uploader(f"ä¸Šå‚³èˆ‡ã€{t_role}ã€‘çš„ç´€éŒ„", type="txt")

        if st.button("âœ¨ ç”ŸæˆåŸºç¤äººè¨­"):
            if up_file:
                with st.spinner("åˆ†æä¸­..."):
                    raw = up_file.read().decode("utf-8")
                    prompt = f"åˆ†æå°è©±ã€‚æˆ‘å°{t_role}çš„èªªè©±é¢¨æ ¼ã€‚å°ˆå±¬æš±ç¨±æ˜¯ã€Œ{nickname}ã€ã€‚è«‹ç”ŸæˆSystem Promptï¼Œå¼·èª¿å¿…é ˆä½¿ç”¨æš±ç¨±ç¨±å‘¼å°æ–¹ã€‚è³‡æ–™ï¼š{raw[-20000:]}"
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    save_persona_summary(t_role, res.choices[0].message.content)
                    st.success("åŸºç¤äººè¨­å·²æ›´æ–°ï¼")

    # --- TAB 2: å›æ†¶è£œå®Œè¨ˆç•« (æ–°åŠŸèƒ½) ---
    with tab2:
        st.caption("é€éå›ç­”å•é¡Œï¼Œè£œå……ç”Ÿæ´»ç´°ç¯€ï¼Œè®“ AI æ›´æ‡‚ä½ å€‘")
        
        # 1. é¸æ“‡è§’è‰²
        q_role = st.selectbox("æ‚¨æƒ³è£œå……é—œæ–¼èª°çš„å›æ†¶ï¼Ÿ", list(INTERVIEW_QUESTIONS.keys()), key="q_role")
        
        # 2. éš¨æ©Ÿæˆ–é¸æ“‡é¡Œç›®
        q_list = INTERVIEW_QUESTIONS.get(q_role, ["è«‹åˆ†äº«ä¸€å€‹é—œæ–¼ä½ å€‘çš„å›æ†¶"])
        question = st.selectbox("è«‹é¸æ“‡ä¸€å€‹è©±é¡Œä¾†å›ç­”ï¼š", q_list)
        
        st.markdown(f'<div class="question-card"><b>APP æå•ï¼š</b><br>{question}</div>', unsafe_allow_html=True)
        
        # 3. å›ç­”å€ (å¯éŒ„éŸ³æˆ–æ‰“å­—)
        ans_method = st.radio("å›ç­”æ–¹å¼", ["èªéŸ³å£è¿°", "æ–‡å­—è¼¸å…¥"], horizontal=True)
        
        answer_content = ""
        if ans_method == "èªéŸ³å£è¿°":
            audio_ans = st.audio_input("æŒ‰æ­¤å›ç­”å•é¡Œ", key="ans_rec")
            if audio_ans:
                trans = client.audio.transcriptions.create(model="whisper-1", file=audio_ans)
                answer_content = trans.text
        else:
            answer_content = st.text_area("è¼¸å…¥æ‚¨çš„å›ç­”...")

        if st.button("ğŸ’¾ å­˜å…¥å¤§è…¦"):
            if answer_content:
                # çµ„åˆå•é¡Œèˆ‡ç­”æ¡ˆå­˜å…¥
                full_memory = f"ã€é—œæ–¼{question}ã€‘ï¼š{answer_content}"
                save_memory_fragment(q_role, full_memory)
                st.success("å·²å­˜å…¥æ·±å±¤è¨˜æ†¶ï¼AI ä¹‹å¾Œæœƒè¨˜å¾—é€™ä»¶äº‹ã€‚")
                st.balloons()
            else:
                st.warning("è«‹å…ˆè¼¸å…¥æˆ–éŒ„è£½å›ç­”")

    # --- TAB 3: è²éŸ³ç‰¹è¨“å®¤ (æ–°åŠŸèƒ½) ---
    with tab3:
        st.caption("è¦ºå¾—è²éŸ³ä¸åƒï¼Ÿåœ¨é€™è£¡å¤šéŒ„å¹¾æ®µä¸åŒæƒ…ç·’çš„è²éŸ³ä¸Šå‚³ï¼Œè¨“ç·´ AIã€‚")
        
        st.info("ğŸ’¡ å»ºè­°éŒ„è£½å…§å®¹ï¼š\n1. ç”¨é–‹å¿ƒçš„èªæ°£å«å–šè¦ªäººçš„åå­—ã€‚\n2. è¬›ä¸€æ®µå®‰æ…°äººçš„è©±ã€‚\n3. å¤§ç¬‘æˆ–æ¿€å‹•çš„èªæ°£ã€‚")
        
        train_audio = st.audio_input("éŒ„è£½è¨“ç·´æ¨£æœ¬ (ç´„ 1 åˆ†é˜)", key="train_rec")
        
        if train_audio:
            if st.button("ğŸš€ ä¸Šå‚³ä¸¦å¾®èª¿æ¨¡å‹"):
                with st.spinner("æ­£åœ¨å‚³é€è‡³ ElevenLabs é€²è¡Œå¾®èª¿..."):
                    success = train_voice_sample(train_audio)
                    if success:
                        st.success("è¨“ç·´æˆåŠŸï¼è«‹ç­‰å¾…å¹¾åˆ†é˜è®“æ¨¡å‹æ›´æ–°ï¼Œè²éŸ³æœƒè®Šå¾—æ›´è‡ªç„¶ã€‚")
                    else:
                        st.error("ä¸Šå‚³å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– API Key æ¬Šé™ã€‚")