import streamlit as st
import requests
from openai import OpenAI
from supabase import create_client, Client
import numpy as np
import os
import json

# --- 1. é é¢èˆ‡ UI è¨­å®š ---
st.set_page_config(page_title="æƒ³å¿µ", page_icon="ğŸ¤", layout="centered")

custom_css = """
<style>
    .stApp, p, h1, h2, h3, label, div, span { color: #333333 !important; }
    div[data-baseweb="select"] > div { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li { background-color: #FFFFFF !important; color: #333333 !important; }
    div[data-baseweb="popover"] li:hover { background-color: #E3F2FD !important; }
    .ai-bubble {
        background-color: #FFFFFF;
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        border-left: 5px solid #4A90E2;
        margin: 10px 0;
        color: #333333;
    }
    .question-card {
        background-color: #E3F2FD;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
        border: 1px solid #BBDEFB;
        font-size: 18px;
        font-weight: bold;
    }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- 2. åˆå§‹åŒ– ---
if "SUPABASE_URL" not in st.secrets or "ADMIN_PASSWORD" not in st.secrets:
    st.error("âš ï¸ è«‹å…ˆè¨­å®š Secrets")
    st.stop()

openai_key = st.secrets["OPENAI_API_KEY"]
elevenlabs_key = st.secrets["ELEVENLABS_API_KEY"]
voice_id = st.secrets["VOICE_ID"]
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
admin_password = st.secrets["ADMIN_PASSWORD"]

client = OpenAI(api_key=openai_key)

@st.cache_resource
def init_supabase():
    return create_client(supabase_url, supabase_key)

supabase = init_supabase()

# --- 3. è®€å–å¤–éƒ¨é¡Œåº« (JSON) ---
@st.cache_data
def load_questions_from_file():
    """è®€å– questions.json æª”æ¡ˆ"""
    try:
        with open('questions.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {"éŒ¯èª¤": ["æ‰¾ä¸åˆ° questions.json é¡Œåº«æª”ï¼Œè«‹ç¢ºèªå·²ä¸Šå‚³è‡³ GitHub"]}
    except Exception as e:
        return {"éŒ¯èª¤": [f"è®€å–å¤±æ•—: {e}"]}

question_db = load_questions_from_file()

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

def get_embedding(text):
    text = text.replace("\n", " ")
    return client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding

def save_memory_fragment(role, text_content):
    """å„²å­˜å–®æ¢è¨˜æ†¶ç‰‡æ®µ"""
    embedding = get_embedding(text_content)
    data = {"role": role, "content": text_content, "embedding": embedding}
    supabase.table("memories").insert(data).execute()
    return True

def search_relevant_memories(role, query_text):
    try:
        query_vec = get_embedding(query_text)
        response = supabase.rpc(
            "match_memories",
            {"query_embedding": query_vec, "match_threshold": 0.5, "match_count": 3, "search_role": role}
        ).execute()
        return "\n".join([item['content'] for item in response.data])
    except: return ""

def save_persona_summary(role, content):
    data = {"role": role, "content": content}
    supabase.table("personas").upsert(data).execute()

def load_all_roles():
    try:
        res = supabase.table("personas").select("role").execute()
        return [i['role'] for i in res.data]
    except: return []

def load_persona(role):
    try:
        res = supabase.table("personas").select("content").eq("role", role).execute()
        return res.data[0]['content'] if res.data else None
    except: return None

# --- ä¸Šå‚³éŒ„éŸ³åˆ° ElevenLabs (å«æ¨™ç±¤) ---
def train_voice_sample(audio_bytes, label="General"):
    """
    å°‡éŒ„éŸ³æª”å‚³é€çµ¦ ElevenLabs
    label: ç”¨ä¾†æ¨™è¨˜é€™æ˜¯ä»€éº¼éŒ„éŸ³ (ä¾‹å¦‚: Nickname_Wife)
    """
    try:
        url = f"https://api.elevenlabs.io/v1/voices/{voice_id}/edit"
        headers = {"xi-api-key": elevenlabs_key}
        
        # æº–å‚™æª”æ¡ˆ
        files = {
            'files': (f'{label}.mp3', audio_bytes, 'audio/mpeg')
        }
        data = {'name': 'My Digital Clone'} 
        
        response = requests.post(url, headers=headers, data=data, files=files)
        return response.status_code == 200
    except Exception as e:
        st.error(f"ä¸Šå‚³å¤±æ•—: {e}")
        return False

# --- 5. æ¬Šé™ç®¡ç† ---
if "is_admin" not in st.session_state: st.session_state.is_admin = False

def check_pass():
    if st.session_state.pwd_input == admin_password:
        st.session_state.is_admin = True
        st.session_state.pwd_input = ""
    else: st.error("å¯†ç¢¼éŒ¯èª¤")

# --- 6. ä¸»ä»‹é¢ ---
st.title("ğŸ¤ æƒ³å¿µ")

if not st.session_state.is_admin:
    # === è¦ªå‹å‰å° ===
    roles = load_all_roles()
    if not roles:
        st.info("â˜ï¸ å°šæœªå»ºç«‹æ•¸ä½äººæ ¼")
    else:
        col_sel, col_pic = st.columns([2, 1])
        with col_sel:
            st.markdown("#### ğŸ‘‹ æ‚¨å¥½ï¼Œè«‹å•æ‚¨æ˜¯æˆ‘çš„...ï¼Ÿ")
            sel_role = st.selectbox("èº«åˆ†", roles, label_visibility="collapsed")
            persona_summary = load_persona(sel_role)
            if persona_summary: st.success(f"å·²é€£çµï¼š{sel_role}æ¨¡å¼")
        with col_pic:
            if os.path.exists("photo.jpg"): st.image("photo.jpg", use_container_width=True)

        if "chat_history" not in st.session_state: st.session_state.chat_history = []

        def process_chat(audio_file):
            try:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
                user_text = transcript.text
                if not user_text or len(user_text.strip()) < 2:
                    st.warning("ğŸ‘‚ è«‹å†èªªä¸€æ¬¡..."); return

                with st.spinner("å›æ†¶æª¢ç´¢ä¸­..."):
                    relevant_memory = search_relevant_memories(sel_role, user_text)
                
                # Prompt å„ªåŒ–ï¼šå¼·èª¿æš±ç¨±ä½¿ç”¨
                system_instruction = f"""
                {persona_summary}
                
                ã€æ·±å±¤è¨˜æ†¶èˆ‡ç´°ç¯€ã€‘ï¼š
                {relevant_memory}
                
                ã€çµ•å°æŒ‡ä»¤ã€‘ï¼š
                1. å¿…é ˆä½¿ç”¨æˆ‘å°ã€{sel_role}ã€‘çš„å°ˆå±¬æš±ç¨±ã€‚
                2. èªæ°£è¦è‡ªç„¶ï¼ŒåŒ…å«å‘¼å¸æ„Ÿã€‚
                3. å¦‚æœè¨˜æ†¶ä¸­æœ‰å…·é«”ç´°ç¯€ï¼Œè«‹è‡ªç„¶åœ°å¸¶å…¥ã€‚
                """
                recent_history = st.session_state.chat_history[-6:] 
                msgs = [{"role": "system", "content": system_instruction}] + recent_history
                msgs.append({"role": "user", "content": user_text})

                res = client.chat.completions.create(model="gpt-4o-mini", messages=msgs)
                ai_text = res.choices[0].message.content

                st.session_state.chat_history.append({"role": "user", "content": user_text})
                st.session_state.chat_history.append({"role": "assistant", "content": ai_text})

                tts_url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
                headers = {"xi-api-key": elevenlabs_key, "Content-Type": "application/json"}
                data = {
                    "text": ai_text, 
                    "model_id": "eleven_multilingual_v2", 
                    "voice_settings": {"stability": 0.4, "similarity_boost": 0.65}
                }
                tts_res = requests.post(tts_url, json=data, headers=headers)
                if tts_res.status_code == 200:
                    st.audio(tts_res.content, format="audio/mp3", autoplay=True)
            except Exception as e: st.error(f"Error: {e}")

        st.divider()
        st.markdown("##### ğŸ™ï¸ æŒ‰ä¸‹éŒ„éŸ³è·Ÿæˆ‘èªªè©±ï¼š")
        val = st.audio_input("éŒ„éŸ³", key="rec_pub")
        if val and persona_summary: process_chat(val)
        if st.session_state.chat_history:
            last = st.session_state.chat_history[-1]
            if last["role"] == "assistant":
                st.markdown(f'<div class="ai-bubble"><b>ç¥‚èªªï¼š</b><br>{last["content"]}</div>', unsafe_allow_html=True)

    st.divider()
    with st.expander("ğŸ”’ æœƒå“¡ç™»å…¥"):
        st.text_input("å¯†ç¢¼", type="password", key="pwd_input", on_change=check_pass)

else:
    # === ç®¡ç†å“¡å¾Œå° ===
    st.success("ğŸ”“ ç®¡ç†å“¡æ¨¡å¼")
    if st.button("ç™»å‡º"):
        st.session_state.is_admin = False
        st.rerun()

    tab1, tab2, tab3 = st.tabs(["ğŸ“ åŸºç¤äººè¨­", "ğŸ§  å›æ†¶è£œå®Œ (é¡Œåº«)", "ğŸ™ï¸ è²éŸ³ç‰¹è¨“ (æš±ç¨±)"])

    # --- TAB 1: åŸºç¤æª”æ¡ˆ (ä¿æŒä¸è®Š) ---
    with tab1:
        st.caption("è¨­å®šå°è©±èªæ°£èˆ‡åŸºç¤è³‡è¨Š")
        c1, c2 = st.columns(2)
        with c1: t_role = st.selectbox("å°è±¡", ["å¦»å­", "ä¸ˆå¤«", "å…’å­", "å¥³å…’", "æœ‹å‹"], key="tr")
        with c2: nickname = st.text_input("æ‚¨å°ä»–/å¥¹çš„å°ˆå±¬æš±ç¨±", placeholder="ä¾‹å¦‚ï¼šå¯¶è²ã€å°èƒ–", key="nk")
        
        up_file = st.file_uploader(f"ä¸Šå‚³èˆ‡ã€{t_role}ã€‘çš„ç´€éŒ„", type="txt")

        if st.button("âœ¨ ç”ŸæˆåŸºç¤äººè¨­"):
            if up_file:
                with st.spinner("åˆ†æä¸­..."):
                    raw = up_file.read().decode("utf-8")
                    prompt = f"åˆ†æå°è©±ã€‚ä¸»è§’å°{t_role}çš„èªªè©±é¢¨æ ¼ã€‚å°ˆå±¬æš±ç¨±æ˜¯ã€Œ{nickname}ã€ã€‚è«‹ç”ŸæˆSystem Promptï¼Œå¼·èª¿å¿…é ˆä½¿ç”¨æš±ç¨±ã€Œ{nickname}ã€ç¨±å‘¼å°æ–¹ã€‚è³‡æ–™ï¼š{raw[-20000:]}"
                    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                    save_persona_summary(t_role, res.choices[0].message.content)
                    st.success("åŸºç¤äººè¨­å·²æ›´æ–°ï¼")

    # --- TAB 2: å›æ†¶è£œå®Œ (è®€å– JSON) ---
    with tab2:
        st.caption("æ¯å¤©å›ç­”å¹¾é¡Œï¼Œè®“ AI çš„è¨˜æ†¶æ›´å®Œæ•´")
        
        q_role = st.selectbox("æ‚¨æƒ³è£œå……é—œæ–¼èª°çš„å›æ†¶ï¼Ÿ", list(question_db.keys()), key="q_role")
        
        # å¾ JSON è®€å–é¡Œç›®åˆ—è¡¨
        q_list = question_db.get(q_role, ["(ç„¡é¡Œç›®è³‡æ–™)"])
        
        # éš¨æ©ŸæŒ‰éˆ•
        if st.button("ğŸ² éš¨æ©Ÿæ›ä¸€é¡Œ"):
             question = np.random.choice(q_list)
             st.session_state.current_q = question
        elif "current_q" not in st.session_state:
             st.session_state.current_q = q_list[0]
            
        st.markdown(f'<div class="question-card"><b>APP æå•ï¼š</b><br>{st.session_state.current_q}</div>', unsafe_allow_html=True)
        
        ans_method = st.radio("å›ç­”æ–¹å¼", ["èªéŸ³å£è¿°", "æ–‡å­—è¼¸å…¥"], horizontal=True)
        answer_content = ""
        if ans_method == "èªéŸ³å£è¿°":
            audio_ans = st.audio_input("æŒ‰æ­¤å›ç­”å•é¡Œ", key="ans_rec")
            if audio_ans:
                trans = client.audio.transcriptions.create(model="whisper-1", file=audio_ans)
                answer_content = trans.text
        else:
            answer_content = st.text_area("è¼¸å…¥æ‚¨çš„å›ç­”...")

        if st.button("ğŸ’¾ å­˜å…¥å¤§è…¦"):
            if answer_content:
                full_memory = f"ã€é—œæ–¼{st.session_state.current_q}ã€‘ï¼š{answer_content}"
                save_memory_fragment(q_role, full_memory)
                st.success("å·²å­˜å…¥æ·±å±¤è¨˜æ†¶ï¼")
                st.balloons()

    # --- TAB 3: è²éŸ³ç‰¹è¨“ (æš±ç¨±å„ªåŒ–) ---
    with tab3:
        st.subheader("ğŸ¯ å°ˆå±¬æš±ç¨±å®šéŒ¨")
        st.info("ç‚ºäº†è®“ AI å«å–šè¦ªäººçš„åå­—æ›´åƒæ‚¨ï¼Œè«‹åœ¨é€™è£¡ç‰¹åˆ¥éŒ„è£½è©²æš±ç¨±ã€‚")
        
        target_nick = st.text_input("è¼¸å…¥æ‚¨è¦éŒ„è£½çš„æš±ç¨±æ–‡å­—", placeholder="ä¾‹å¦‚ï¼šè€å©†ï½")
        
        col_t1, col_t2 = st.columns(2)
        
        with col_t1:
            st.markdown("##### æ­¥é©Ÿ 1ï¼šéŒ„è£½æš±ç¨±")
            st.caption("è«‹åªéŒ„è£½é‚£å€‹ç¨±å‘¼ï¼Œèªæ°£è¦åƒå¹³å¸¸å«å¥¹ä¸€æ¨£ã€‚å»ºè­°éŒ„ 3-5 ç§’ã€‚")
            nick_audio = st.audio_input("éŒ„è£½æš±ç¨±", key="nick_rec")
            
        with col_t2:
            st.markdown("##### æ­¥é©Ÿ 2ï¼šä¸Šå‚³å®šéŒ¨")
            if nick_audio and target_nick:
                if st.button("ğŸš€ ä¸Šå‚³æš±ç¨±æ¨£æœ¬"):
                    with st.spinner("æ­£åœ¨é€²è¡Œæ¬Šé‡å¾®èª¿..."):
                        # ä½¿ç”¨ç‰¹æ®Šçš„ label æ¨™è¨˜
                        success = train_voice_sample(nick_audio, label=f"Nickname_{target_nick}")
                        if success:
                            st.success(f"æˆåŠŸï¼å·²è®“ AI è¨˜ä½ã€Œ{target_nick}ã€çš„ç™¼éŸ³æ–¹å¼ã€‚")
                        else:
                            st.error("ä¸Šå‚³å¤±æ•—")
            else:
                st.caption("è«‹å…ˆè¼¸å…¥æ–‡å­—ä¸¦éŒ„éŸ³")
        
        st.divider()
        st.subheader("ğŸ™ï¸ ä¸€èˆ¬æƒ…ç·’è¨“ç·´")
        st.caption("éŒ„è£½é•·å¥ï¼ˆé–‹å¿ƒã€ç”Ÿæ°£ã€å®‰æ…°ï¼‰ä»¥è±å¯Œèªèª¿ã€‚")
        gen_audio = st.audio_input("éŒ„è£½é•·å¥", key="gen_rec")
        if gen_audio:
            if st.button("ä¸Šå‚³æƒ…ç·’æ¨£æœ¬"):
                if train_voice_sample(gen_audio, label="Emotion_Sample"):
                    st.success("è¨“ç·´æˆåŠŸ")